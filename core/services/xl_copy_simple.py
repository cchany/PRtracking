import calendar
from datetime import datetime
from io import BytesIO
import re
import requests
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from openpyxl.utils import range_boundaries

# ===================== ë¶„ë¥˜ ì²´ê³„(ë²”ìœ„ + ì‹œì¥) =====================
GEOS = ["ì „ì„¸ê³„", "í•œêµ­", "ì¤‘êµ­", "ìœ ëŸ½", "ë¯¸êµ­", "ì¼ë³¸", "ì¸ë„"]
MARKETS = [
    "ìŠ¤ë§ˆíŠ¸í°", "í´ë”ë¸” ìŠ¤ë§ˆíŠ¸í°", "ìŠ¤ë§ˆíŠ¸í° AP",
    "AI", "XR", "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜",
    "ë³´ì•ˆ",
    "TV", "OLED", "LCD TV", "ë””ìŠ¤í”Œë ˆì´",
    "ë¡œë´‡ì²­ì†Œê¸°", "ë¡œë´‡",
    "ë°˜ë„ì²´",
    "ì „ê¸°ì°¨",
]

# í—ˆìš© ì¹´í…Œê³ ë¦¬(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸): "ë²”ìœ„ ì‹œì¥" ì „ ì¡°í•©
ALLOWED_CATEGORIES = {f"{g} {m} ì‹œì¥" for g in GEOS for m in MARKETS}
ALLOWED_CATEGORIES.add("ë¯¸ë¶„ë¥˜")

def _to_whitelist(cat: str) -> str:
    """í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë°–ì´ë©´ 'ë¯¸ë¶„ë¥˜'ë¡œ ë³´ì •"""
    return cat if cat in ALLOWED_CATEGORIES else "ë¯¸ë¶„ë¥˜"

# ---------------- ì§€ë¦¬/ë„ë©”ì¸ íŒ¨í„´ ----------------
# <ë²”ìœ„> â€” ì¼ë°˜ í‚¤ì›Œë“œ + â€˜ì§€ì—­ëª… â€¦ ì‹œì¥/marketâ€™ íŒ¨í„´ê¹Œì§€ ì¸ì‹
GEO_PATTERNS = {
    "ì „ì„¸ê³„": r"(ì „\s*ì„¸ê³„.{0,20}ì‹œì¥|ê¸€ë¡œë²Œ.{0,20}ì‹œì¥|ì „\s*ì„¸ê³„|ì „ì„¸ê³„|ì„¸ê³„|ê¸€ë¡œë²Œ)",
    "í•œêµ­":   r"(í•œêµ­.{0,20}ì‹œì¥|ëŒ€í•œë¯¼êµ­.{0,20}ì‹œì¥|êµ­ë‚´.{0,20}ì‹œì¥|í•œêµ­|ëŒ€í•œë¯¼êµ­|\bêµ­ë‚´\b)",
    "ì¤‘êµ­":   r"(ì¤‘êµ­.{0,20}ì‹œì¥|ì¤‘êµ­)",
    "ìœ ëŸ½":   r"(ìœ ëŸ½.{0,20}ì‹œì¥|ìœ ëŸ½)",
    "ë¯¸êµ­":   r"(ë¯¸êµ­.{0,20}ì‹œì¥|ë¯¸êµ­)",
    "ì¼ë³¸":   r"(ì¼ë³¸.{0,20}ì‹œì¥|ì¼ë³¸)",
    "ì¸ë„":   r"(ì¸ë„.{0,20}ì‹œì¥|ì¸ë„)",
}

# <ì‹œì¥> íŒ¨í„´ (ì—…ë°ì´íŠ¸ í¬í•¨)
DOMAIN_PATTERNS = {
    "í´ë”ë¸” ìŠ¤ë§ˆíŠ¸í°": r"(í´ë”ë¸”\s*ìŠ¤ë§ˆíŠ¸í°|í´ë”ë¸”|í´ë¨ì…¸|í´ë¨ì‰˜|í”Œë¦½|í”Œë¦½í°|flip\b|fold\b|razr|ë ˆì´ì €)",
    "ìŠ¤ë§ˆíŠ¸í° AP": r"(\bAP\b|ëª¨ë°”ì¼\s*AP|\bSoC\b|chipset|ì¹©ì…‹|AP\s*ì›ê°€|AP\s*ë¹„ìš©|AP\s*ê³µì •)",
    # ğŸ”§ ìŠ¤ë§ˆíŠ¸í°: 'ì‹œì¥' ê·¼ì ‘ ë‹¨ì„œë¡œ ì œí•œ(ì‚¬ì´ë“œë°”/ì—°ê´€ê¸€ ë…¸ì´ì¦ˆ ë°©ì§€)
    "ìŠ¤ë§ˆíŠ¸í°": (
        r"((ìŠ¤ë§ˆíŠ¸í°|smart\s*phone|ì‚¼ì„±í°|ì• í”Œí°|mobile\s*phone|íœ´ëŒ€í°).{0,15}ì‹œì¥|"
        r"ì‹œì¥.{0,15}(ìŠ¤ë§ˆíŠ¸í°|smart\s*phone|ì‚¼ì„±í°|ì• í”Œí°|mobile\s*phone|íœ´ëŒ€í°))"
    ),

    "AI": r"(\bAI\b|ì¸ê³µì§€ëŠ¥|ìƒì„±í˜•\s*AI|Generative\s*AI|ChatGPT|Copilot|Gemini|LLM)",
    "XR": r"(\bXR\b|\bAR\b|\bVR\b|\bMR\b|í—¤ë“œì…‹|ìŠ¤ë§ˆíŠ¸\s*ì•ˆê²½|ìŠ¤ë§ˆíŠ¸ì•ˆê²½)",
    "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜": r"(ìŠ¤ë§ˆíŠ¸\s*ì›Œì¹˜|smart\s*watch|ì›¨ì–´ëŸ¬ë¸”)",

    "ë³´ì•ˆ": r"(ë³´ì•ˆ|ì‚¬ì´ë²„\s*ë³´ì•ˆ|ì‚¬ì´ë²„\s*ìœ„í˜‘|ì‚¬ì´ë²„ìœ„í˜‘|ìœ„í˜‘|cyber\s*security|security)",

    "TV": r"(?:(?:\bTV\b|í‹°ë¹„|television)(?:\s*ì‹œì¥)?)",
    "OLED": r"(?:OLED\s*TV\s*ì‹œì¥|OLED\s*ì‹œì¥|ì˜¬ë ˆë“œ\s*ì‹œì¥|OLED\s*TV)",
    "LCD TV": r"(?:LCD\s*TV\s*ì‹œì¥|LCD\s*ì‹œì¥)",
    "ë””ìŠ¤í”Œë ˆì´": r"(?:(?:ë””ìŠ¤í”Œë ˆì´|PC)(?!.{0,15}(?:TV|í‹°ë¹„|OLED|ì˜¬ë ˆë“œ|LCD))(?:\s*ì‹œì¥)?|ë””ìŠ¤í”Œë ˆì´ ì‹œì¥|PC)",

    "ë¡œë´‡ì²­ì†Œê¸°": r"(ë¡œë´‡\s*ì²­ì†Œê¸°|ì²­ì†Œ\s*ë¡œë´‡|robot\s*vacuum|vacuum\s*robot|ë¡œë³´ë½|Ecovacs|Dreame)",
    "ë¡œë´‡": r"(ë¡œë´‡\b|ë¡œë´‡ê³µí•™|ì„œë¹„ìŠ¤\s*ë¡œë´‡|ì‚°ì—…ìš©\s*ë¡œë´‡|ì œì¡°ìš©\s*ë¡œë´‡|ë¡œë´‡ì‚°ì—…)",

    "ë°˜ë„ì²´": r"(ë°˜ë„ì²´|íŒŒìš´ë“œë¦¬|foundry|ì¹©\b|chips\b|chip\b|ë©”ëª¨ë¦¬|memory|HBM|\bDRAM\b|D-?RAM|\bNAND\b|Dë¨|ë””ë¨|ì—ì´ì¹˜ë¹„ì— |"
             r"í•˜ì´ë‹‰ìŠ¤|ì—”ë¹„ë””ì•„|NVIDIA|AMD|ì¸í…”|Intel|TSMC|ë§ˆì´í¬ë¡ |Micron|wafer|fab|íŒ¨í‚¤ì§•)",
    "ì „ê¸°ì°¨": r"(ì „ê¸°ì°¨\b|ì „ê¸°ì°¨\s*ì‹œì¥|electric\s*vehicle|\bEV\b|\bBEV\b|\bPHEV\b)",
}

# ë„ë©”ì¸ ìš°ì„ ìˆœìœ„ (ì„¸ë¶€ â†’ ì¼ë°˜)
DOMAIN_PRIORITY = [
    "í´ë”ë¸” ìŠ¤ë§ˆíŠ¸í°", "ìŠ¤ë§ˆíŠ¸í° AP",
    "OLED", "LCD TV", "TV",
    "XR", "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜",
    "ë³´ì•ˆ",
    "ë¡œë´‡ì²­ì†Œê¸°", "ë¡œë´‡",
    "ë°˜ë„ì²´",
    "ì „ê¸°ì°¨",
    "ë””ìŠ¤í”Œë ˆì´",
    "AI",
    "ìŠ¤ë§ˆíŠ¸í°",
]

# ---------------- ëª…ì‹œì  "<ë²”ìœ„><ì‹œì¥> ì‹œì¥" ìµœìš°ì„  íƒì§€ ----------------
def _compile_explicit_patterns():
    geo_tokens = {
        "ì „ì„¸ê³„": r"(ì „\s*ì„¸ê³„.{0,20}ì‹œì¥|ê¸€ë¡œë²Œ.{0,20}ì‹œì¥|ì „\s*ì„¸ê³„|ì „ì„¸ê³„|ì„¸ê³„|ê¸€ë¡œë²Œ)",
        "í•œêµ­":   r"(í•œêµ­.{0,20}ì‹œì¥|ëŒ€í•œë¯¼êµ­.{0,20}ì‹œì¥|êµ­ë‚´.{0,20}ì‹œì¥|í•œêµ­|ëŒ€í•œë¯¼êµ­|\bêµ­ë‚´\b)",
        "ì¤‘êµ­":   r"(ì¤‘êµ­.{0,20}ì‹œì¥|ì¤‘êµ­)",
        "ìœ ëŸ½":   r"(ìœ ëŸ½.{0,20}ì‹œì¥|ìœ ëŸ½)",
        "ë¯¸êµ­":   r"(ë¯¸êµ­.{0,20}ì‹œì¥|ë¯¸êµ­)",
        "ì¼ë³¸":   r"(ì¼ë³¸.{0,20}ì‹œì¥|ì¼ë³¸)",
        "ì¸ë„":   r"(ì¸ë„.{0,20}ì‹œì¥|ì¸ë„)",
    }
    market_tokens = {
        "ìŠ¤ë§ˆíŠ¸í°": r"(ìŠ¤ë§ˆíŠ¸í°|smart\s*phone|ì‚¼ì„±í°|ì• í”Œí°|íœ´ëŒ€í°|mobile\s*phone)",
        "í´ë”ë¸” ìŠ¤ë§ˆíŠ¸í°": r"(í´ë”ë¸”\s*ìŠ¤ë§ˆíŠ¸í°|í´ë”ë¸”|í”Œë¦½|í´ë“œ|flip\b|fold\b|í´ë¨ì…¸|í´ë¨ì‰˜|razr|ë ˆì´ì €)",
        "ìŠ¤ë§ˆíŠ¸í° AP": r"(\bAP\b|ëª¨ë°”ì¼\s*AP|\bSoC\b|chipset|ì¹©ì…‹)",
        "AI": r"(\bAI\b|ì¸ê³µì§€ëŠ¥|ìƒì„±í˜•\s*AI|Generative\s*AI|ChatGPT|Copilot|Gemini|LLM)",
        "XR": r"(\bXR\b|\bAR\b|\bVR\b|\bMR\b|í—¤ë“œì…‹|ìŠ¤ë§ˆíŠ¸\s*ì•ˆê²½|ìŠ¤ë§ˆíŠ¸ì•ˆê²½)",
        "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜": r"(ìŠ¤ë§ˆíŠ¸\s*ì›Œì¹˜|smart\s*watch|wearable)",
        "ë³´ì•ˆ": r"(ë³´ì•ˆ|ì‚¬ì´ë²„\s*ë³´ì•ˆ|ì‚¬ì´ë²„\s*ìœ„í˜‘|cyber\s*security|security)",
        "TV": r"(?:\bTV\b|í‹°ë¹„)",
        "OLED": r"(?:OLED\s*TV|OLED|ì˜¬ë ˆë“œ)",
        "LCD TV": r"(?:LCD-?TV|LCD)",
        "ë””ìŠ¤í”Œë ˆì´": r"(ë””ìŠ¤í”Œë ˆì´|PC)",
        "ë¡œë´‡ì²­ì†Œê¸°": r"(ë¡œë´‡\s*ì²­ì†Œê¸°|ì²­ì†Œ\s*ë¡œë´‡|robot\s*vacuum)",
        "ë¡œë´‡": r"(ë¡œë´‡\b|ë¡œë´‡ê³µí•™|ì„œë¹„ìŠ¤\s*ë¡œë´‡|ì‚°ì—…ìš©\s*ë¡œë´‡|ì œì¡°ìš©\s*ë¡œë´‡)",
        "ë°˜ë„ì²´": r"(ë°˜ë„ì²´|íŒŒìš´ë“œë¦¬|foundry|ì¹©\b|í•˜ì´ë‹‰ìŠ¤|ë©”ëª¨ë¦¬|HBM|DRAM|NAND|Dë¨|ë””ë¨|TSMC|Intel|ì¸í…”|Micron|ë§ˆì´í¬ë¡ )",
        "ì „ê¸°ì°¨": r"(ì „ê¸°ì°¨|electric\s*vehicle|\bEV\b|\bBEV\b|\bPHEV\b)",
    }
    patterns = []
    for g, gtok in geo_tokens.items():
        for m, mtok in market_tokens.items():
            # <ë²”ìœ„> ... <ì‹œì¥> ... ì‹œì¥
            p1 = rf"({gtok}).{{0,30}}({mtok}).{{0,10}}ì‹œì¥"
            # <ì‹œì¥> ... ì‹œì¥ ... <ë²”ìœ„>
            p2 = rf"({mtok}).{{0,10}}ì‹œì¥.{0,30}({gtok})"
            patterns.append((g, m, re.compile(p1, re.I)))
            patterns.append((g, m, re.compile(p2, re.I)))
    return patterns

EXPLICIT_PATTERNS = _compile_explicit_patterns()

# ---------------- ë‹¤ì¤‘ êµ­ê°€ â†’ 'ì „ì„¸ê³„' ê°•ì œ ê·œì¹™ ----------------
_GEO_TOKEN_SPECIFIC = [
    r"(í•œêµ­|ëŒ€í•œë¯¼êµ­|\bêµ­ë‚´\b)",
    r"(ì¤‘êµ­)",
    r"(ìœ ëŸ½)",
    r"(ë¯¸êµ­)",
    r"(ì¼ë³¸)",
    r"(ì¸ë„)",
]
_GEO_TOKEN_GLOBAL = r"(ì „\s*ì„¸ê³„|ì „ì„¸ê³„|ê¸€ë¡œë²Œ|global|worldwide)"
GEO_RE_SPECIFICS = [re.compile(p, re.I) for p in _GEO_TOKEN_SPECIFIC]
GEO_RE_GLOBAL = re.compile(_GEO_TOKEN_GLOBAL, re.I)

def _multi_geo_triggers_world(text: str) -> bool:
    t = text or ""
    specific_hits = 0
    for rx in GEO_RE_SPECIFICS:
        if rx.search(t):
            specific_hits += 1
        if specific_hits >= 2:
            return True
    if specific_hits >= 1 and GEO_RE_GLOBAL.search(t):
        return True
    return False

def _find_explicit_geo_market(text: str):
    """
    ë³¸ë¬¸ì— '<ë²”ìœ„><ì‹œì¥> ì‹œì¥' ëª…ì‹œê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì¡°í•© ì¦‰ì‹œ ë°˜í™˜.
    ë‹¨, ë‹¤ì¤‘ êµ­ê°€ ê·œì¹™ì´ íŠ¸ë¦¬ê±°ë˜ë©´ ë²”ìœ„ëŠ” 'ì „ì„¸ê³„'ë¡œ ê°•ì œ.
    """
    if _multi_geo_triggers_world(text):
        for g, m, rx in EXPLICIT_PATTERNS:
            if rx.search(text or ""):
                return "ì „ì„¸ê³„", m
        return "ì „ì„¸ê³„", None
    t = text or ""
    for g, m, rx in EXPLICIT_PATTERNS:
        if rx.search(t):
            return g, m
    return None, None

# ---------------- ê³µí†µ ìœ í‹¸ ----------------
def _copy_range_values(src_ws, dst_ws, src_range: str, dst_top_left: str):
    min_col, min_row, max_col, max_row = range_boundaries(src_range)
    col_letters = "".join([c for c in dst_top_left if c.isalpha()])
    row_digits = "".join([c for c in dst_top_left if c.isdigit()])
    dst_row0 = int(row_digits)
    dst_col0 = 0
    for i, ch in enumerate(reversed(col_letters.upper())):
        dst_col0 += (ord(ch) - 64) * (26 ** i)
    rows = max_row - min_row + 1
    cols = max_col - min_col + 1
    for r in range(rows):
        for c in range(cols):
            val = src_ws.cell(row=min_row + r, column=min_col + c).value
            dst_ws.cell(row=dst_row0 + r, column=dst_col0 + c, value=val)

def _rename_if_exists(wb, candidates, new_name):
    for name in candidates:
        if name in wb.sheetnames:
            wb[name].title = new_name
            return True
    last = candidates[-1] if candidates else None
    if last and last.startswith("re:"):
        rx = re.compile(last[3:], re.I)
        for s in wb.sheetnames:
            if rx.match(s):
                wb[s].title = new_name
                return True
    return False

def _fill_auto_numbers(ws, start_row: int = 5, col: int = 1, max_rows: int = 800):
    count = 0
    for i in range(start_row, max_rows + 1):
        val = ws.cell(row=i, column=2).value
        if val is None or str(val).strip() == "":
            break
        count += 1
        ws.cell(row=i, column=col, value=count)

def _update_countif_formulas(ws, month, base_sheet="CP"):
    for row in range(7, 501):
        ws[f"K{row}"] = f'=COUNTIF({base_sheet}_{month}!G:G,L{row})'

# ---------------- í¬ë¡¤ë§(ì¸í„°ë„·) ----------------
def _fetch_article_text(url: str) -> str:
    """
    ê¸°ì‚¬ ë³¸ë¬¸ë§Œ ìµœëŒ€í•œ ê¹¨ë—í•˜ê²Œ ì¶”ì¶œ.
    - í—¤ë”/í‘¸í„°/ë„¤ë¹„/ì‚¬ì´ë“œë°”/ìŠ¤í¬ë¦½íŠ¸ ì œê±° (ë…¸ì´ì¦ˆ ì°¨ë‹¨)
    - ì—¬ëŸ¬ í›„ë³´ ì»¨í…Œì´ë„ˆë¥¼ íƒìƒ‰
    """
    if not url or not isinstance(url, str) or not url.startswith(("http://", "https://")):
        return ""
    try:
        res = requests.get(url.strip(), timeout=5, headers={"User-Agent": "Mozilla/5.0"})
        if res.status_code != 200:
            return ""
        soup = BeautifulSoup(res.text, "html.parser")

        # ë…¸ì´ì¦ˆê°€ í° ì˜ì—­ ì œê±°
        for sel in ["header", "nav", "footer", "aside", "script", "style", ".sidebar", ".breadcrumbs", ".breadcrumb", ".related", ".recommend", ".ad", ".ads"]:
            for n in soup.select(sel):
                n.decompose()

        selectors = [
            "article", ".article", "#articleBody", "#articeBody", "#news_body",
            ".news_body", ".article_body", ".article-body", ".content", "#content",
            ".post-content", ".entry-content", ".post_body", ".post-body"
        ]
        nodes = []
        for sel in selectors:
            nodes = soup.select(sel)
            if nodes:
                break
        if nodes:
            text = " ".join(n.get_text(separator=" ", strip=True) for n in nodes)
        else:
            text = soup.get_text(separator=" ", strip=True)

        return (text or "")[:4000]
    except Exception:
        return ""

# ---------------- ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ----------------
def _regex_search(pattern, text):
    return re.search(pattern, text, flags=re.I) is not None

def _pick_geo(text):
    # ë‹¤ì¤‘ êµ­ê°€ ê·œì¹™ ìš°ì„  ì ìš©
    if _multi_geo_triggers_world(text):
        return "ì „ì„¸ê³„"
    # ëª…ì‹œì /ì¼ë°˜ ì§€ë¦¬ íŒ¨í„´
    for geo, patt in GEO_PATTERNS.items():
        if _regex_search(patt, text):
            return geo
    return None

def _pick_domain(text):
    for key in DOMAIN_PRIORITY:
        patt = DOMAIN_PATTERNS[key]
        if _regex_search(patt, text):
            return key
    return None

def _compose_category(geo_label, domain_label):
    geo = geo_label if geo_label in GEOS else "ì „ì„¸ê³„"
    dom = domain_label if domain_label in MARKETS else "ìŠ¤ë§ˆíŠ¸í°"
    return f"{geo} {dom} ì‹œì¥"

def _classify_category_for_row(text_concat: str, source_hint: str):
    t = (text_concat or "")

    # 1) ëª…ì‹œ "<ë²”ìœ„><ì‹œì¥> ì‹œì¥" ìµœìš°ì„ 
    eg, em = _find_explicit_geo_market(t)
    if em:
        # ë””ìŠ¤í”Œë ˆì´ ì¼ë°˜ì´ë©´ì„œ ê°™ì€ ë¬¸ì¥ì— TV/OLED/LCDê°€ ìˆìœ¼ë©´ ì„¸ë¶€ë¡œ ì¬ê²°ì •
        if em == "ë””ìŠ¤í”Œë ˆì´" and _regex_search(r"(TV|í‹°ë¹„|OLED|ì˜¬ë ˆë“œ|LCD)", t):
            dm = _pick_domain(t) or "ë””ìŠ¤í”Œë ˆì´"
            return _to_whitelist(_compose_category(eg if eg else "ì „ì„¸ê³„", dm))
        return _to_whitelist(_compose_category(eg if eg else "ì „ì„¸ê³„", em))

    # 2) ì¼ë°˜ ê·œì¹™: ë„ë©”ì¸ â†’ ì§€ë¦¬ (ë‹¤ì¤‘êµ­ê°€ ê·œì¹™ì€ _pick_geo ë‚´ë¶€ì—ì„œ ì²˜ë¦¬)
    geo = _pick_geo(t)
    domain = _pick_domain(t)
    if domain:
        return _to_whitelist(_compose_category(geo if geo else "ì „ì„¸ê³„", domain))

    # 3) ì†ŒìŠ¤ ë³´ì • (ë””ìŠ¤í”Œë ˆì´ ì „ë¬¸ ì†ŒìŠ¤)
    if source_hint in ("OmdiaTV", "DSCC"):
        return _to_whitelist(_compose_category(geo if geo else "ì „ì„¸ê³„", "ë””ìŠ¤í”Œë ˆì´"))

    # 4) ìµœì¢… ê¸°ë³¸ê°’: ì–´ë–¤ ê·œì¹™ë„ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ 'ë¯¸ë¶„ë¥˜'
    return "ë¯¸ë¶„ë¥˜"

# ---------------- ì¹´í…Œê³ ë¦¬ ì…ë ¥ ë£¨í‹´ ----------------
def _fill_categories(ws, source_hint: str, start_row: int = 5, max_rows: int = 800):
    for r in range(start_row, max_rows + 1):
        bval = ws.cell(row=r, column=2).value
        e_text = ws.cell(row=r, column=5).value
        f_url  = ws.cell(row=r, column=6).value
        if not (bval or e_text or f_url):
            break

        text_source = (str(e_text).strip() if e_text else "")

        # ğŸ”§ ìš”ì•½ë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´(20â†’100ì)ë§Œ URL ë³¸ë¬¸ì„ ë³´ê°•í•´ì„œ ì‚¬ìš©
        if len(text_source) < 100 and f_url:
            fetched = _fetch_article_text(str(f_url))
            if fetched:
                text_source = fetched

        cat = _classify_category_for_row(text_source, source_hint)
        ws.cell(row=r, column=7, value=cat)

# ---------------- ë©”ì¸ ì²˜ë¦¬ ----------------
def process_monthly_copy(raw_bytes: bytes, monthly_bytes: bytes, month: int) -> bytes:
    raw_wb = load_workbook(BytesIO(raw_bytes), data_only=True)
    mon_wb = load_workbook(BytesIO(monthly_bytes))
    m = int(month)

    # ì‹œíŠ¸ëª… ë³€ê²½
    _rename_if_exists(mon_wb, ["CP_9", "cp_9", "CP-9", "re:^CP[_ -]?9$"], f"CP_{m}")
    _rename_if_exists(mon_wb, ["CP_9_work", "CP_9_Work", "re:^CP[_ -]?9[_ -]?work$"], f"CP_{m}_work")
    _rename_if_exists(mon_wb, ["IDC_9", "re:^IDC[_ -]?9$"], f"IDC_{m}")
    _rename_if_exists(mon_wb, ["IDC_9_work", "re:^IDC[_ -]?9[_ -]?work$"], f"IDC_{m}_work")
    _rename_if_exists(mon_wb, ["OmdiaTV_9", "Omdia TV_9", "re:^Omdia\s?TV[_ -]?9$"], f"OmdiaTV_{m}")
    _rename_if_exists(mon_wb, ["OmdiaTV_9_work", "Omdia TV_9_work", "re:^Omdia\s?TV[_ -]?9[_ -]?work$"], f"OmdiaTV_{m}_work")
    _rename_if_exists(mon_wb, ["DSCC_9", "re:^DSCC[_ -]?9$"], f"DSCC_{m}")
    _rename_if_exists(mon_wb, ["DSCC_9_work", "re:^DSCC[_ -]?9[_ -]?work$"], f"DSCC_{m}_work")
    _rename_if_exists(mon_wb, [f"9ì›” ì´í‰", "re:^9\s*ì›”\s*ì´í‰$"], f"{m}ì›” ì´í‰")

    # RAW â†’ ì›” ì‹œíŠ¸ ê°’ ë³µì‚¬
    _copy_range_values(raw_wb["CPR"],      mon_wb[f"CP_{m}"],      "B5:B800", "B5")
    _copy_range_values(raw_wb["CPR"],      mon_wb[f"CP_{m}"],      "D5:G800", "C5")
    _copy_range_values(raw_wb["IDC"],      mon_wb[f"IDC_{m}"],     "B5:B800", "B5")
    _copy_range_values(raw_wb["IDC"],      mon_wb[f"IDC_{m}"],     "D5:G800", "C5")
    _copy_range_values(raw_wb["Omdia TV"], mon_wb[f"OmdiaTV_{m}"], "B5:B800", "B5")
    _copy_range_values(raw_wb["Omdia TV"], mon_wb[f"OmdiaTV_{m}"], "D5:G800", "C5")
    _copy_range_values(raw_wb["DSCC"],     mon_wb[f"DSCC_{m}"],    "B5:B800", "B5")
    _copy_range_values(raw_wb["DSCC"],     mon_wb[f"DSCC_{m}"],    "D5:G800", "C5")

    # ë²ˆí˜¸ ë§¤ê¸°ê¸°
    for name in [f"CP_{m}", f"IDC_{m}", f"OmdiaTV_{m}", f"DSCC_{m}"]:
        _fill_auto_numbers(mon_wb[name])

    # A2 ìˆ˜ì‹ ì—…ë°ì´íŠ¸ (IDC/OmdiaTV/DSCC)
    for name in [f"IDC_{m}", f"OmdiaTV_{m}", f"DSCC_{m}"]:
        mon_wb[name]["A2"] = f"=CP_{m}!A2"
        
    # âœ… CP_{m} ì‹œíŠ¸ A2 ë‚ ì§œ ìë™ ì—…ë°ì´íŠ¸
    current_year = datetime.now().year
    last_day = calendar.monthrange(current_year, m)[1]
    start_date = f"{current_year}/{m:02d}/01"
    end_date = f"{current_year}/{m:02d}/{last_day:02d}"
    mon_wb[f"CP_{m}"]["A2"] = f"[ê¸°ê°„] {start_date}~ {end_date}"

    # ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜ (Gì—´)
    _fill_categories(mon_wb[f"CP_{m}"],      "CP")
    _fill_categories(mon_wb[f"IDC_{m}"],     "IDC")
    _fill_categories(mon_wb[f"OmdiaTV_{m}"], "OmdiaTV")
    _fill_categories(mon_wb[f"DSCC_{m}"],    "DSCC")

    out = BytesIO()
    mon_wb.save(out)
    out.seek(0)
    return out.getvalue()
